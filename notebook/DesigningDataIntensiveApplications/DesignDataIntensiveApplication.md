# Designing Data-Intensive Application

> https://vonng.gitbooks.io/ddia-cn/content/part-i.html

## Part1 数据系统的基石

### 可靠性，可扩展性，可维护性

![](https://vonng.gitbooks.io/ddia-cn/content/img/ch1.png)

- 相关概念
  - 数据密集型和计算密集型
  - 数据系统
    - 数据库
    - 缓存
    - 消息队列
  - 可靠性
    - 故障和失效的差异，是否还能继续提供服务
    - 平均无故障时间
  - 可扩展性
    - 负载
    - 吞吐量
    - 相应时间和延迟
    - 
  - 可维护性
  - 

> 补充
>
> - redis实现消息队列的方式：https://blog.csdn.net/qq_35029061/article/details/126663745
> - 

#### 可靠性

人们对于一个东西是否可靠，都有一个直观的想法。人们对可靠软件的典型期望包括：

* 应用程序表现出用户所期望的功能。
* 允许用户犯错，允许用户以出乎意料的方式使用软件。
* 在预期的负载和数据量下，性能满足要求。
* 系统能防止未经授权的访问和滥用

> - 据报道称，硬盘的 **平均无故障时间（MTTF mean time to failure）** 约为10到50年【5】【6】。因此从数学期望上讲，在拥有10000个磁盘的存储集群上，平均每天会有1个磁盘出故障。
> - 闰秒导致的Linux内核错误

造成可靠性问题：

- 硬件故障
- 软件错误
- 认为错误

#### 可扩展性

**可扩展性（Scalability）** 是用来描述系统应对负载增长能力的术语。但是请注意，这不是贴在系统上的一维标签：说“X可扩展”或“Y不可扩展”是没有任何意义的。相反，讨论可扩展性意味着考虑诸如“如果系统以特定方式增长，有什么选项可以应对增长？”和“如何增加计算资源来处理额外的负载？”等问题

> **推特的推文系统设计：**
>
>> 推文发布后需要合并到订阅者的时间线中
>>
>
> - 时间线模型
> - 扇入、扇出的请求数量
>
> 1. 发布推文时，只需将新推文插入全局推文集合即可。当一个用户请求自己的主页时间线时，首先查找他关注的所有人，查询这些被关注用户发布的推文并按时间顺序合并。
> 2. 为每个用户的主页时间线维护一个缓存，就像每个用户的推文收件箱。 当一个用户发布推文时，查找所有关注该用户的人，并将新的推文插入到每个主页时间线缓存中。
> 3. 结合1 2，对大V单独使用模式1
>
> 推特的第一个版本使用了方法1，但系统很难跟上主页时间线查询的负载。所以公司转向了方法2，方法2的效果更好，因为发推频率比查询主页时间线的频率几乎低了两个数量级，所以在这种情况下，最好在写入时做更多的工作，而在读取时做更少的工作。
>
> 然而方法2的缺点是，发推现在需要大量的额外工作。平均来说，一条推文会发往约75个关注者，所以每秒4.6k的发推写入，变成了对主页时间线缓存每秒345k的写入。但这个平均值隐藏了用户粉丝数差异巨大这一现实，一些用户有超过3000万的粉丝，这意味着一条推文就可能会导致主页时间线缓存的3000万次写入！及时完成这种操作是一个巨大的挑战 —— 推特尝试在5秒内向粉丝发送推文。
>
> 在推特的例子中，每个用户粉丝数的分布（可能按这些用户的发推频率来加权）是探讨可扩展性的一个关键负载参数，因为它决定了扇出负载。你的应用程序可能具有非常不同的特征，但可以采用相似的原则来考虑它的负载。
>
> 推特轶事的最终转折：现在已经稳健地实现了方法2，推特逐步转向了两种方法的混合。大多数用户发的推文会被扇出写入其粉丝主页时间线缓存中。但是少数拥有海量粉丝的用户（即名流）会被排除在外。当用户读取主页时间线时，分别地获取出该用户所关注的每位名流的推文，再与用户的主页时间线缓存合并，如方法1所示。这种混合方法能始终如一地提供良好性能。在[第12章](https://vonng.gitbooks.io/ddia-cn/content/ch12.html)中我们将重新讨论这个例子，这在覆盖更多技术层面之后。

**吞吐量（throughput）** ，即每秒可以处理的记录数量，或者在特定规模数据集上运行作业的总时间。

**响应时间（response time）** ，即客户端发送请求到接收响应之间的时间。

**延迟（latency）** 和 **响应时间（response time）** 经常用作同义词，但实际上它们并不一样。响应时间是客户所看到的，除了实际处理请求的时间（ **服务时间（service time）** ）之外，还包括网络延迟和排队延迟。延迟是某个请求等待处理的 **持续时长** ，在此期间它处于 **休眠（latent）** 状态，并等待服务。

> 不同的响应时间统计方式对应的不同问题类型：
>
> - **算术平均值（arithmetic mean）** ：给定 n 个值，加起来除以 n ）。然而如果你想知道“ **典型（typical）** ”响应时间，那么平均值并不是一个非常好的指标，因为它不能告诉你有多少用户实际上经历了这个延迟。
> - **百分位点（percentiles）** 会更好。如果将响应时间列表按最快到最慢排序，那么 **中位数（median）** 就在正中间。
>   - 如果想知道典型场景下用户需要等待多长时间，那么中位数是一个好的度量标准：一半用户请求的响应时间少于响应时间的中位数，另一半服务时间比中位数长。中位数也被称为第50百分位点，有时缩写为p50。
>   - 响应时间的高百分位点（也称为 **尾部延迟（tail latencies）** ）非常重要，因为它们直接影响用户的服务体验。
>   - 百分位点通常用于 **服务级别目标（SLO, service level objectives）** 和 **服务级别协议（SLA, service level agreements）** ，即定义服务预期性能和可用性的合同。 SLA可能会声明，如果服务响应时间的中位数小于200毫秒，且99.9百分位点低于1秒，则认为服务工作正常（如果响应时间更长，就认为服务不达标）。这些指标为客户设定了期望值，并允许客户在SLA未达标的情况下要求退款。
> - **排队延迟（queueing delay）** 通常占了高百分位点处响应时间的很大一部分。由于服务器只能并行处理少量的事务（如受其CPU核数的限制），所以只要有少量缓慢的请求就能阻碍后续请求的处理，这种效应有时被称为 **头部阻塞（head-of-line blocking）** 。即使后续请求在服务器上处理的非常迅速，由于需要等待先前请求完成，客户端最终看到的是缓慢的总体响应时间。因为存在这种效应，测量客户端的响应时间非常重要。

应对负载的方式：

- 纵向扩展：更强的机器
- 横向扩展：更多地机器

> - 有些系统是 **弹性（elastic）** 的，这意味着可以在检测到负载增加时自动增加计算资源，而其他系统则是手动扩展（人工分析容量并决定向系统添加更多的机器）。如果负载 **极难预测（highly unpredictable）** ，则弹性系统可能很有用，但手动扩展系统更简单，并且意外操作可能会更少（参阅“[重新平衡分区](https://vonng.gitbooks.io/ddia-cn/content/ch6.html#%E5%88%86%E5%8C%BA%E5%86%8D%E5%B9%B3%E8%A1%A1)”）。
> - 跨多台机器部署 **无状态服务（stateless services）** 非常简单，但将带状态的数据系统从单节点变为分布式配置则可能引入许多额外复杂度。出于这个原因，常识告诉我们应该将数据库放在单个节点上（纵向扩展），直到扩展成本或可用性需求迫使其改为分布式。
> - 

#### 可维护性

众所周知，软件的大部分开销并不在最初的开发阶段，而是在持续的维护阶段，包括修复漏洞、保持系统正常运行、调查失效、适配新的平台、为新的场景进行修改、偿还技术债、添加新的功能等等。

特别关注软件系统的三个设计原则：

***可操作性（Operability）***

 便于运维团队保持系统平稳运行。

***简单性（Simplicity）***

 从系统中消除尽可能多的 **复杂度（complexity）** ，使新工程师也能轻松理解系统。（注意这和用户接口的简单性不一样。）

***可演化性（evolability）***

 使工程师在未来能轻松地对系统进行更改，当需求变化时为新应用场景做适配。也称为 **可扩展性（extensibility）** ， **可修改性（modifiability）** 或 **可塑性（plasticity）** 。


### 数据模型与查询语言

> 多数应用使用层层叠加的数据模型，对于每层数据模型的关键问题是如何使用低一层的数据模型来表示数据。

- 关系模型和文档模型
- NoSQL，Not Only SQL
- 对象关系不匹配
  - 存储id还是文本字符串问题
  - 连接问题
- 网络模型
  - 访问路径
  - 

> 通过存储模型的发展历史说明随着场景的变化，不同的存储模型的优缺点，以及各自适应的场景。



























##### end dog
